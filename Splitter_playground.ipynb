{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Splitter_playground.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyModdlPIbVt9QPvrAfouvB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pren1/VAST/blob/master/Splitter_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czEROTY595JP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twI28paZ7ETZ",
        "colab_type": "code",
        "outputId": "138afcc0-d701-4067-8fb6-56fbbb838bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "!rm -rf VAST/\n",
        "!git clone https://github.com/pren1/VAST.git\n",
        "!pip3 install soundfile\n",
        "!pip3 install librosa"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'VAST'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 150 (delta 69), reused 66 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (150/150), 47.09 MiB | 10.38 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.3)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.18.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.48.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (46.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.31.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAbJHx787OHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from VAST.util import *\n",
        "import pdb\n",
        "import pprint\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import IPython\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import os\n",
        "from tqdm import trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAksJZUD7OWN",
        "colab_type": "code",
        "outputId": "2a32910d-ccba-4eaa-f0ad-0f2e0ce774f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfYr7P78cWiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adapted from Keith Ito's tacotron implementation\n",
        "# https://github.com/keithito/tacotron/blob/master/util/audio.py\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Audio():\n",
        "    def __init__(self):\n",
        "        self.ref_level_db = 20.0\n",
        "        self.n_fft = 1200\n",
        "        self.hop_length = 160\n",
        "        self.win_length = 400\n",
        "        self.min_level_db = -100.0\n",
        "\n",
        "    def wav2spec(self, y):\n",
        "        D = self.stft(y)\n",
        "        S = self.amp_to_db(np.abs(D)) - self.ref_level_db\n",
        "        S, D = self.normalize(S), np.angle(D)\n",
        "        S, D = S.T, D.T # to make [time, freq]\n",
        "        return S, D\n",
        "\n",
        "    def spec2wav(self, spectrogram, phase):\n",
        "        spectrogram, phase = spectrogram.T, phase.T\n",
        "        # used during inference only\n",
        "        # spectrogram: enhanced output\n",
        "        # phase: use noisy input's phase, so no GLA is required\n",
        "        S = self.db_to_amp(self.denormalize(spectrogram) + self.ref_level_db)\n",
        "        return self.istft(S, phase)\n",
        "\n",
        "    def stft(self, y):\n",
        "        return librosa.stft(y=y, n_fft=self.n_fft,\n",
        "                            hop_length=self.hop_length,\n",
        "                            win_length=self.win_length)\n",
        "\n",
        "    def istft(self, mag, phase):\n",
        "        stft_matrix = mag * np.exp(1j*phase)\n",
        "        return librosa.istft(stft_matrix,\n",
        "                             hop_length=self.hop_length,\n",
        "                             win_length=self.win_length)\n",
        "\n",
        "    def amp_to_db(self, x):\n",
        "        return 20.0 * np.log10(np.maximum(1e-5, x))\n",
        "\n",
        "    def db_to_amp(self, x):\n",
        "        return np.power(10.0, x * 0.05)\n",
        "\n",
        "    def normalize(self, S):\n",
        "        return np.clip(S / -self.min_level_db, -1.0, 0.0) + 1.0\n",
        "\n",
        "    def denormalize(self, S):\n",
        "        return (np.clip(S, 0.0, 1.0) - 1.0) * -self.min_level_db\n",
        "\n",
        "audio = Audio()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo7t986-nHjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.asarray([[ 0.67218363, -1.6871625 ,  0.39094335,  0.45416522,  3.060402  ,\n",
        "        -2.87009   , -0.29556486, -1.8322845 ,  2.287039  , -1.5228181 ,\n",
        "         2.8732414 ,  2.1143398 , -3.355237  , -0.4983314 , -2.6186857 ,\n",
        "         1.3060979 , -0.8364598 , -0.9532552 , -0.22835416,  0.8867765 ,\n",
        "         1.5227174 ,  1.2176653 , -0.9880353 , -0.32890812,  2.618597  ,\n",
        "        -2.7140734 , -2.3689802 ,  0.7710235 ,  1.9084004 ,  0.8810432 ,\n",
        "         2.6237597 , -2.6608293 ],\n",
        "         [-0.8265083 , -1.6049656 ,  1.5085448 ,  0.6589694 ,  2.1224942 ,\n",
        "         2.3647609 ,  0.11735925,  1.1543381 ,  0.99229884,  1.4278704 ,\n",
        "         0.5712279 , -1.5206277 ,  0.30854183, -2.6490169 ,  1.3902934 ,\n",
        "        -0.23975304,  0.94975144, -2.0093975 ,  0.17497058, -1.0554106 ,\n",
        "        -2.172874  , -1.5222347 ,  0.563387  ,  2.239781  , -0.96120906,\n",
        "        -0.42689592,  2.4739625 , -2.362247  , -0.98188835,  0.16969077,\n",
        "        -0.6247616 ,  0.04511972],\n",
        "        [ 0.0985966 ,  0.9150637 ,  2.2399673 , -2.6504104 , -1.3134806 ,\n",
        "        -1.8142706 , -0.18147974, -1.2972969 , -1.2393317 ,  1.5120008 ,\n",
        "         0.9399936 , -0.15138409,  1.557585  ,  0.6709012 , -2.143024  ,\n",
        "         1.276797  , -0.5063797 ,  2.5019035 ,  0.11260484,  1.5303274 ,\n",
        "         1.7554147 ,  1.4767547 ,  2.4642498 ,  1.399184  , -1.5406029 ,\n",
        "         2.0078533 ,  0.1091506 ,  1.1654673 ,  0.0777089 ,  1.4040853 ,\n",
        "        -0.7952607 , -0.1732147 ],\n",
        "        [ 0.47638106,  1.8903663 , -2.9872196 ,  2.3670852 , -2.4623342 ,\n",
        "         2.220159  ,  0.23939389,  1.5010741 , -0.7784126 , -0.54998654,\n",
        "        -2.0378437 , -0.07159348,  0.3601075 ,  1.7380389 ,  2.3474126 ,\n",
        "        -1.0004979 ,  0.47312295, -0.88486624,  0.18921344, -0.43055353,\n",
        "         0.38867134,  0.00616272, -3.2682106 , -2.6373188 ,  2.909382  ,\n",
        "         0.7305331 , -1.1071701 ,  0.9580342 , -1.1098799 , -1.7031851 ,\n",
        "         0.00362744,  2.3521018 ]\n",
        "         ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ7EoJwKnICJ",
        "colab_type": "code",
        "outputId": "18c87087-3f09-4488-a01c-d4c7e365af07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwUWhLBm7VN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "def trunk_network(conv_size = 64, LSTM_size = 400, input_size = (51, 601), dropout_rate = 0.0):\n",
        "    inputs = tf.keras.layers.Input(input_size)\n",
        "\n",
        "    speaker_embeddings = tf.keras.Input(shape=(1, 32), dtype=tf.float32)\n",
        "    \n",
        "    x = tf.keras.layers.Reshape((input_size[0],  input_size[1], 1))(inputs)\n",
        "    # cnn1\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((0, 0), (3, 3)))(x)\n",
        "    x = tf.keras.layers.Conv2D(conv_size, (1, 7))(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # cnn2\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((3, 3), (0, 0)))(x)\n",
        "    x = tf.keras.layers.Conv2D(conv_size, (7, 1))(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # cnn3\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((2, 2), (2, 2)))(x)\n",
        "    x = tf.keras.layers.Conv2D(conv_size, (5, 5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # # cnn1\n",
        "    # x = tf.keras.layers.ZeroPadding2D(padding=((0, 0), (3, 3)))(x)\n",
        "    # x = tf.keras.layers.Conv2D(conv_size, (1, 7))(x)\n",
        "    # x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.layers.ReLU()(x)\n",
        "    # x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # # cnn2\n",
        "    # x = tf.keras.layers.ZeroPadding2D(padding=((3, 3), (0, 0)))(x)\n",
        "    # x = tf.keras.layers.Conv2D(conv_size, (7, 1))(x)\n",
        "    # x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.layers.ReLU()(x)\n",
        "    # x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # cnn3\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((2, 2), (2, 2)))(x)\n",
        "    x = tf.keras.layers.Conv2D(conv_size, (5, 5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # cnn3\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((2, 2), (2, 2)))(x)\n",
        "    x = tf.keras.layers.Conv2D(conv_size, (5, 5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # cnn3\n",
        "    x = tf.keras.layers.ZeroPadding2D(padding=((2, 2), (2, 2)))(x)\n",
        "    x = tf.keras.layers.Conv2D(conv_size, (5, 5))(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # # # cnn4\n",
        "    # x = tf.keras.layers.ZeroPadding2D(padding=((4, 4), (2, 2)))(x)\n",
        "    # x = tf.keras.layers.Conv2D(conv_size, (5, 5), dilation_rate=(2, 1))(x)\n",
        "    # x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.layers.ReLU()(x)\n",
        "    # pdb.set_trace()\n",
        "\n",
        "    # # cnn5\n",
        "    # x = tf.keras.layers.ZeroPadding2D(padding=((8, 8), (2, 2)))(x)     \n",
        "    # x = tf.keras.layers.Conv2D(conv_size, (5, 5), dilation_rate=(4, 1))(x)       \n",
        "    # x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "    # # cnn6\n",
        "    # x = tf.keras.layers.ZeroPadding2D(padding=((16, 16), (2, 2)))(x)                 \n",
        "    # x = tf.keras.layers.Conv2D(conv_size, (5, 5), dilation_rate=(8, 1))(x) \n",
        "    # x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "    # # cnn7 TensorShape([None, 51, 601, conv_size])\n",
        "    # x = tf.keras.layers.ZeroPadding2D(padding=((32, 32), (2, 2)))(x)\n",
        "    # x = tf.keras.layers.Conv2D(conv_size, (5, 5), dilation_rate=(16, 1))(x)     \n",
        "    # x = tf.keras.layers.BatchNormalization()(x)\n",
        "    # x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "    # cnn8 TensorShape([None, 51, 601, 8])\n",
        "    x = tf.keras.layers.Conv2D(8, (1, 1))(x)     \n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    'Reshape x shape TensorShape([None, 51, 4808])'\n",
        "    # x = tf.keras.layers.Reshape((tf.keras.backend.int_shape(x)[1], tf.keras.backend.int_shape(x)[2]*tf.keras.backend.int_shape(x)[3]))(x)\n",
        "    x = tf.keras.layers.Reshape((51, 4808))(x)\n",
        "    repeat_embedding_time_wise = tf.tile(speaker_embeddings, [1, 51, 1])\n",
        "    \n",
        "    x = tf.keras.layers.concatenate([x, repeat_embedding_time_wise],axis=-1)\n",
        "    # LSTM 1\n",
        "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_size, return_sequences=True)\n",
        "                            )(x)  # [b_s, seq_len, vec_dim]\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)                        \n",
        "\n",
        "    # # LSTM 2 TensorShape([None, 51, 800])                                           \n",
        "    # x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_size, return_sequences=True)\n",
        "    #                         )(x)  # [b_s, seq_len, vec_dim]\n",
        "\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    # Dense 1\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_size[1]))(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    # Dense 2\n",
        "    mask = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(input_size[1], activation='sigmoid'))(x)\n",
        "\n",
        "    output = tf.keras.layers.Multiply()([inputs, mask])\n",
        "    # print(output.shape)\n",
        "    model = tf.keras.Model(inputs=[inputs, speaker_embeddings], outputs=[output])\n",
        "    return model\n",
        "\n",
        "'learning rate decay'\n",
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.5\n",
        "    epochs_drop = 10.0\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
        "    return lrate    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBwhSxHcVS1E",
        "colab_type": "text"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehDMj2ac7S-",
        "colab_type": "code",
        "outputId": "fc8624cd-0d36-453f-ceca-8cf9a7208e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "with strategy.scope():\n",
        "  model = trunk_network(conv_size = 64, LSTM_size = 400)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss=['mse'])\n",
        "  lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.26.150.58:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.26.150.58:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.26.150.58:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.26.150.58:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylpzMlb5jQL2",
        "colab_type": "code",
        "outputId": "e1b3f8d2-b4a6-447d-c179-8ae06b788f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 51, 601)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 51, 601, 1)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 51, 607, 1)   0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 51, 601, 64)  512         zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 51, 601, 64)  256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 51, 601, 64)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 51, 601, 64)  0           re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 57, 601, 64)  0           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 51, 601, 64)  28736       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 51, 601, 64)  256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 51, 601, 64)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 51, 601, 64)  0           re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 55, 605, 64)  0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 51, 601, 64)  102464      zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 51, 601, 64)  256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 51, 601, 64)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 51, 601, 64)  0           re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 55, 605, 64)  0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 51, 601, 64)  102464      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 51, 601, 64)  256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 51, 601, 64)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 51, 601, 64)  0           re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 55, 605, 64)  0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 51, 601, 64)  102464      zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 51, 601, 64)  256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 51, 601, 64)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 51, 601, 64)  0           re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 55, 605, 64)  0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 51, 601, 64)  102464      zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 51, 601, 64)  256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 51, 601, 64)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 51, 601, 64)  0           re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 51, 601, 8)   520         dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 51, 601, 8)   32          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 51, 601, 8)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 51, 601, 8)   0           re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 1, 32)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 51, 4808)     0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Tile (TensorFlowOpL [(None, 51, 32)]     0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 51, 4840)     0           reshape_1[0][0]                  \n",
            "                                                                 tf_op_layer_Tile[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 51, 800)      16771200    concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 51, 800)      0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 51, 800)      0           dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 51, 601)      481401      re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 51, 601)      0           time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 51, 601)      0           re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 51, 601)      361802      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 51, 601)      0           input_1[0][0]                    \n",
            "                                                                 time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 18,055,595\n",
            "Trainable params: 18,054,811\n",
            "Non-trainable params: 784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh0dRFif6CcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_total = []\n",
        "# y_total = []\n",
        "\n",
        "# for i in tqdm(range(67)):\n",
        "#   X_total.append(np.load(f\"gdrive/My Drive/Spitter_VTB/mixed_mag/{i}.npy\", allow_pickle=True))\n",
        "#   y_total.append(np.load(f\"gdrive/My Drive/Spitter_VTB/target_mag/{i}.npy\", allow_pickle=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2tNcUeOHFL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def mix(s1_target, s2):\n",
        "#   srate = 8000\n",
        "#   w1 = s1_target\n",
        "#   w2 = s2\n",
        "\n",
        "#   mixed = w1 + w2\n",
        "#   norm = np.max(np.abs(mixed)) * 1.1\n",
        "#   w1, w2, mixed = w1/norm, w2/norm, mixed/norm\n",
        "\n",
        "#   target_mag, _ = audio.wav2spec(w1)\n",
        "#   mixed_mag, mixed_phase = audio.wav2spec(mixed)\n",
        "#   return target_mag, mixed_mag, mixed_phase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2FqBm4pHMM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import random\n",
        "\n",
        "# def generate_data_on_the_fly(batch_size, spk1_source_data, spk2_source_data):\n",
        "#   spk1_index = np.random.choice(range(len(spk1_source_data)), batch_size)\n",
        "#   spk1 = spk1_source_data[spk1_index]\n",
        "  \n",
        "#   spk2_index = np.random.choice(range(len(spk2_source_data)), batch_size)\n",
        "#   spk2 = spk2_source_data[spk2_index]\n",
        "#   target_mag_list = []\n",
        "#   mixed_mag_list = []\n",
        "#   mixed_phase_list = []\n",
        "#   for (s1_target, s2) in zip(spk1, spk2):\n",
        "#     target_mag, mixed_mag, mixed_phase = mix(s1_target, s2)\n",
        "#     target_mag_list.append(target_mag)\n",
        "#     mixed_mag_list.append(mixed_mag)\n",
        "#     mixed_phase_list.append(mixed_phase)\n",
        "#   return  np.asarray(target_mag_list), np.asarray(mixed_mag_list), np.asarray(mixed_phase_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89e37UBuHCfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_1 = load_data_array_from_npy(\"gdrive/My Drive/Free_RAM_VAST/白上フブキ.npy\")\n",
        "# data_2 = load_data_array_from_npy(\"gdrive/My Drive/Free_RAM_VAST/夏色まつり.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlS2biXSKe7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_ratio = 0.9\n",
        "# spk1_source_data = data_1[:int(train_ratio * len(data_1))]\n",
        "# spk2_source_data = data_2[:int(train_ratio * len(data_2))]\n",
        "\n",
        "# spk1_test_data = data_1[int(train_ratio * len(data_1)):]\n",
        "# spk2_test_data = data_2[int(train_ratio * len(data_2)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tul_GerwLCWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spk1_source_data.shape\n",
        "# spk2_source_data.shape\n",
        "# spk1_test_data.shape\n",
        "# spk2_test_data.shapea\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY3qE82UIGm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import time\n",
        "# start_time = time.time()\n",
        "# X, y, _ = generate_data_on_the_fly(256, spk1_source_data, spk2_source_data)\n",
        "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdSz_IPQMw22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss = model.train_on_batch(np.asarray(X), np.asarray(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXGInuCPKckz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_total = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/mixed_mag_list.npy\")\n",
        "# y_total = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/target_mag_list.npy\")\n",
        "# corresponding_phase = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/mixed_phase_list.npy\")\n",
        "\n",
        "# train_ratio = 0.9\n",
        "# X_train = X_total[:int(train_ratio * len(X_total))]\n",
        "# y_train = y_total[:int(train_ratio * len(X_total))]\n",
        "# train_phase = corresponding_phase[:int(train_ratio * len(X_total))]\n",
        "\n",
        "# X_test = X_total[int(train_ratio * len(X_total)):]\n",
        "# y_test = y_total[int(train_ratio * len(X_total)):]\n",
        "# test_phase = corresponding_phase[int(train_ratio * len(X_total)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9SJ-I2yaPbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(\n",
        "#   dataset.batch(32),\n",
        "#   steps_per_epoch=67,\n",
        "#   # batch_size = 512,\n",
        "#   epochs=50,\n",
        "#   callbacks=[lrate]\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSbMNRcXjNRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(3):\n",
        "#   model.fit(\n",
        "#   x = X_total, y = y_total,\n",
        "#   # steps_per_epoch=67,\n",
        "#   batch_size = 512,\n",
        "#   epochs=1,\n",
        "#   # callbacks=[lrate]\n",
        "#   )\n",
        "\n",
        "# model.fit(\n",
        "#   x = X_train, y = y_train,\n",
        "#   # steps_per_epoch=67,\n",
        "#   batch_size = 16,\n",
        "#   validation_data = (X_test, y_test),\n",
        "#   epochs=200,\n",
        "#   callbacks=[lrate]\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJCCGZhq8CT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpb-tUHJ8QqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The batch iterator\n",
        "class BatchIterator:\n",
        "    def __init__(self, data, label, spk_label, batch_size, is_shuffle):\n",
        "        data = np.asarray(data)\n",
        "        label = np.asarray(label)\n",
        "        self.spk_label = np.asarray(spk_label)\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.batch_size = batch_size\n",
        "        self.cursor = 0\n",
        "        self.size = data.shape[0]\n",
        "        self.order = np.arange(self.size)\n",
        "        self.shuffled = False\n",
        "        if is_shuffle:\n",
        "            self.shuffle()\n",
        "\n",
        "    def shuffle(self):\n",
        "        np.random.shuffle(self.order)\n",
        "        # print \"Batch shuffled\"\n",
        "        self.cursor = 0\n",
        "\n",
        "    def next(self):\n",
        "        if self.shuffled==True:\n",
        "            self.shuffled = False\n",
        "        if self.cursor + self.batch_size > self.size:\n",
        "            self.shuffle()\n",
        "            self.shuffled = True\n",
        "        idx = self.order[self.cursor:self.cursor + self.batch_size]\n",
        "        self.cursor += self.batch_size\n",
        "        return self.data[idx], self.label[idx], self.spk_label[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMvHoLTsSfCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_results(model, X_test, y_test, test_label):\n",
        "  test_res = model.predict([X_test, test_label])\n",
        "  mse = (np.square(test_res - y_test)).mean(axis=None)\n",
        "  return mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9pK3R-bUnnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights(f'gdrive/My Drive/Spitter_VTB/{75}_my_model.h5')\n",
        "# model.load_weights(f'gdrive/My Drive/Spitter_VTB/saved_model/115_my_model.h5')\n",
        "model.load_weights(f'gdrive/My Drive/Spitter_VTB/four_speaker.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNZAbQF3zlt2",
        "colab_type": "code",
        "outputId": "fa0fc168-630f-4a06-a16c-a1f3a4089812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "epoch_num = 100\n",
        "# total_file_length = len(spk1_source_data)//256\n",
        "total_file_length = 40000//256\n",
        "iterations = epoch_num * total_file_length\n",
        "\n",
        "iterations = 60\n",
        "X_test = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_test_case/cycle_mixed_mag_list.npy\")\n",
        "y_test = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_test_case/cycle_target_mag_list.npy\")\n",
        "test_label = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_test_case/cycle_speaker_label.npy\")\n",
        "\n",
        "test_label = np.expand_dims(np.matmul(np.eye(4)[np.asarray(test_label)], embedding_matrix), axis=1)\n",
        "data_counter = 0\n",
        "with trange(iterations) as t:\n",
        "  for iteration in t:\n",
        "    # epoch_num = iteration//total_file_length\n",
        "    if True:\n",
        "    # if iteration % total_file_length == 0:\n",
        "      'load X_train'\n",
        "      target_index = data_counter % 60\n",
        "      # X_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/train_case/full_mixed_mag_list_{target_index}.npy\")\n",
        "      # y_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/train_case/full_target_mag_list_{target_index}.npy\")\n",
        "\n",
        "      X_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_train_case/cycle_mixed_mag_list_{target_index}.npy\")\n",
        "      y_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_train_case/cycle_target_mag_list_{target_index}.npy\")\n",
        "      train_label = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_train_case/cycle_speaker_label{target_index}.npy\")\n",
        "\n",
        "      train_label = np.expand_dims(np.matmul(np.eye(4)[np.asarray(train_label)], embedding_matrix), axis=1)\n",
        "\n",
        "      print(f\"New data loaded at {target_index}\")\n",
        "      data_counter += 1\n",
        "      # iterator = BatchIterator(X_train, y_train, train_label, batch_size=256, is_shuffle=True)\n",
        "\n",
        "    model.fit(\n",
        "      x = [X_train, train_label], y = y_train,\n",
        "      # steps_per_epoch=67,\n",
        "      batch_size = 128,\n",
        "      epochs=4,\n",
        "      validation_data = ([X_test, test_label], y_test),\n",
        "      callbacks=[lrate]\n",
        "    )\n",
        "\n",
        "    if iteration % 5 == 0:\n",
        "      model.save_weights(f'gdrive/My Drive/Spitter_VTB/{iteration}_four_speaker_split.h5')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/60 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New data loaded at 0\n",
            "Epoch 1/4\n",
            "25/79 [========>.....................] - ETA: 16s - loss: 0.0075"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/60 [01:40<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1381f32f7e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeA3E7vq3DpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epoch_num = 100\n",
        "# # total_file_length = len(spk1_source_data)//128\n",
        "# total_file_length = 40000//128\n",
        "# iterations = epoch_num * total_file_length\n",
        "\n",
        "# data_counter = 0\n",
        "# with trange(iterations) as t:\n",
        "#   for iteration in t:\n",
        "#     epoch_num = iteration//total_file_length\n",
        "#     if iteration % total_file_length == 0:\n",
        "#       'load X_train'\n",
        "#       target_index = data_counter % 20\n",
        "#       # X_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/train_case/full_mixed_mag_list_{target_index}.npy\")\n",
        "#       # y_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/train_case/full_target_mag_list_{target_index}.npy\")\n",
        "\n",
        "#       X_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_train_case/cycle_mixed_mag_list_{target_index}.npy\")\n",
        "#       y_train = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_train_case/cycle_target_mag_list_{target_index}.npy\")\n",
        "#       train_label = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_train_case/cycle_speaker_label{target_index}.npy\")\n",
        "\n",
        "#       train_label = np.expand_dims(np.matmul(np.eye(2)[np.asarray(train_label)], embedding_matrix), axis=1)\n",
        "\n",
        "#       print(f\"New data loaded at {target_index}\")\n",
        "#       data_counter += 1\n",
        "#       iterator = BatchIterator(X_train, y_train, train_label, batch_size=128, is_shuffle=True)\n",
        "    \n",
        "#     X, y, spk_label = iterator.next()\n",
        "#     # y, X, _ = generate_data_on_the_fly(256, spk1_source_data, spk2_source_data)\n",
        "#     loss = model.train_on_batch([X, spk_label], y)\n",
        "#     t.set_description('epo %i [loss: %f]' % (epoch_num, loss))\n",
        "#     if iteration > 0 and iteration % (total_file_length) == 0:\n",
        "#       'save model..'\n",
        "#       model_save_path = f'gdrive/My Drive/Spitter_VTB/saved_model/{epoch_num + 200}_my_model.h5'\n",
        "#       print(f\"Model saved to {model_save_path}\")\n",
        "#       model.save_weights(model_save_path)\n",
        "#       # X_test = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/test_case/full_mixed_mag_list.npy\")\n",
        "#       # y_test = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/test_case/full_target_mag_list.npy\")\n",
        "\n",
        "#       X_test = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_test_case/cycle_mixed_mag_list.npy\")\n",
        "#       y_test = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_test_case/cycle_target_mag_list.npy\")\n",
        "#       test_label = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_test_case/cycle_speaker_label.npy\")\n",
        "\n",
        "#       test_label = np.expand_dims(np.matmul(np.eye(2)[np.asarray(test_label)], embedding_matrix), axis=1)\n",
        "#       print(f\"At {epoch_num + 200}, test loss is: {evaluate_results(model, X_test, y_test, test_label)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV4pca0yS8ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_total = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/mixed_mag_list.npy\")[-100:]\n",
        "# y_total = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/target_mag_list.npy\")[-100:]\n",
        "# corresponding_phase = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/mixed_phase_list.npy\")[-100:]\n",
        "# X_total.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S14xv46UIt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(f'gdrive/My Drive/Spitter_VTB/four_speaker.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cI9BlkkRVxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_weights(f'gdrive/My Drive/Spitter_VTB/0.75_my_model.h5')\n",
        "# tf.keras.models.load_model(f'gdrive/My Drive/Spitter_VTB/{epoch_num}_my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4AZ3NNTg93Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_res = model.predict([X_test, test_label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxCsPd1mhL88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_res.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iguo1isWfLSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.expand_dims(embedding_matrix[0, :], axis=0).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7FqYldIfNAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_label[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnlhIWbDV9Tq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstruct_wav(mag, phase, plt_name):\n",
        "  resulted_wav = audio.spec2wav(mag, phase)\n",
        "  plt.plot(resulted_wav, color = 'orange', label='resulted_wav')\n",
        "  plt.title(plt_name)\n",
        "  plt.show()\n",
        "  IPython.display.display(IPython.display.Audio(np.asarray(resulted_wav).T, rate=8000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFC_3ufx2UlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_phase = load_data_array_from_npy(f\"gdrive/My Drive/Free_RAM_VAST/cycle_test_case/cycle_mixed_phase_list.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkLltiOMWlNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10, 20):\n",
        "  reconstruct_wav(X_test[i], test_phase[i], \"Mixed voice\")\n",
        "  reconstruct_wav(y_test[i], test_phase[i], \"ground truth\")\n",
        "  reconstruct_wav(test_res[i], test_phase[i], \"prediction\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIJeVD6BfaXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_0_embeddings = np.expand_dims(embedding_matrix[0, :], axis=0)\n",
        "label_1_embeddings = np.expand_dims(embedding_matrix[1, :], axis=0)\n",
        "\n",
        "for i in range(20, 30):\n",
        "  label_0_res = model.predict([np.expand_dims(X_test[i], axis=0), np.expand_dims(label_0_embeddings, axis=0)])\n",
        "  label_1_res = model.predict([np.expand_dims(X_test[i], axis=0), np.expand_dims(label_1_embeddings, axis=0)])\n",
        "\n",
        "  reconstruct_wav(X_test[i], test_phase[i], \"Mixed voice\")\n",
        "  reconstruct_wav(y_test[i], test_phase[i], \"ground truth\")\n",
        "  reconstruct_wav(label_0_res[0], test_phase[i], \"prediction: label 0\")\n",
        "  reconstruct_wav(label_1_res[0], test_phase[i], \"prediction: label 1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtU1FVSRcVwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(20, 30):\n",
        "  reconstruct_wav(X_test[i], test_phase[i], \"Mixed voice\", label=0)\n",
        "  reconstruct_wav(y_test[i], test_phase[i], \"ground truth\", label=0)\n",
        "  reconstruct_wav(test_res[i], test_phase[i], \"prediction\", label=0)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}